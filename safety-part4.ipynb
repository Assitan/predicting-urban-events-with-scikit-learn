{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 4 partial solution:  Improve the machine learning model\n",
    " \n",
    "## Objective\n",
    " \n",
    "- Iteratively improve the model accuracy: use external datasets, work\n",
    "  on feature extraction, and tune hyper-parameters.\n",
    " \n",
    "## Requirements\n",
    " \n",
    "Install the Python package that we have created in our previous milestone, which contains some of the useful functions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting https://public-sym.s3-eu-west-1.amazonaws.com/LP-safety-US-cities/safety-events-cities-1.0.0.tar.gz\n",
      "  Downloading https://public-sym.s3-eu-west-1.amazonaws.com/LP-safety-US-cities/safety-events-cities-1.0.0.tar.gz (2.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: safety-events-cities\n",
      "  Building wheel for safety-events-cities (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for safety-events-cities: filename=safety_events_cities-1.0.0-py3-none-any.whl size=2974 sha256=fd5baae842c890a6e18a67e7c983c4c689b19ef7afcca9e24c6140662646b210\n",
      "  Stored in directory: /home/assitan/.cache/pip/wheels/31/3b/3a/02c5de71c1358088b9a2e6d6c1793ea657f179a14d3a6ec554\n",
      "Successfully built safety-events-cities\n",
      "Installing collected packages: safety-events-cities\n",
      "Successfully installed safety-events-cities-1.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade https://public-sym.s3-eu-west-1.amazonaws.com/LP-safety-US-cities/safety-events-cities-1.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution also requires the `holidays` package,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting holidays\n",
      "  Downloading holidays-0.13-py3-none-any.whl (172 kB)\n",
      "     |████████████████████████████████| 172 kB 6.0 MB/s            \n",
      "\u001b[?25hCollecting korean-lunar-calendar\n",
      "  Downloading korean_lunar_calendar-0.2.1-py3-none-any.whl (8.0 kB)\n",
      "Collecting convertdate>=2.3.0\n",
      "  Downloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "     |████████████████████████████████| 47 kB 15.9 MB/s            \n",
      "\u001b[?25hCollecting hijri-converter\n",
      "  Downloading hijri_converter-2.2.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3/dist-packages (from holidays) (2.7.3)\n",
      "Collecting pymeeus<=1,>=0.3.13\n",
      "  Downloading PyMeeus-0.5.11.tar.gz (5.4 MB)\n",
      "     |████████████████████████████████| 5.4 MB 16.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pymeeus\n",
      "  Building wheel for pymeeus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymeeus: filename=PyMeeus-0.5.11-py3-none-any.whl size=730984 sha256=5120d8720a78c20d0974e7861b671c5ef07d2c3bd6f8400e5b92457bf6ab044a\n",
      "  Stored in directory: /home/assitan/.cache/pip/wheels/a0/8b/b2/810ae5a6f970c8be4725353400d643c90de1c0f023a9884ee7\n",
      "Successfully built pymeeus\n",
      "Installing collected packages: pymeeus, korean-lunar-calendar, hijri-converter, convertdate, holidays\n",
      "Successfully installed convertdate-2.4.0 hijri-converter-2.2.3 holidays-0.13 korean-lunar-calendar-0.2.1 pymeeus-0.5.11\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# this plugin requires to run \\\"pip install nb-black\\\"\\n%load_ext nb_black\\n\\n# Reload modules automatically when importing code\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"# this plugin requires to run \\\"pip install nb-black\\\"\\n%load_ext nb_black\\n\\n# Reload modules automatically when importing code\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this plugin requires to run \"pip install nb-black\"\n",
    "%load_ext nb_black\n",
    "\n",
    "# Reload modules automatically when importing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\n\\nimport matplotlib.pyplot as plt  # noqa\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\n\\nimport matplotlib.pyplot as plt  # noqa\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by list most frequent categories, for future reference,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"x = pd.read_parquet(\\\"data/safety-SanFrancisco-2.parquet\\\")\";\n",
       "                var nbb_formatted_code = \"x = pd.read_parquet(\\\"data/safety-SanFrancisco-2.parquet\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.read_parquet(\"data/safety-SanFrancisco-2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `load_data` function created in the previous milestone, that filters the data to 2016-2019, select one category, and count the number of events per neighborhood for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Mission</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>Ingleside</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>Mission</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dateTime neighborhood  count\n",
       "0 2016-01-01 00:00:00      Mission      2\n",
       "1 2016-01-01 00:00:00     Nob Hill      1\n",
       "2 2016-01-01 06:00:00    Ingleside      1\n",
       "3 2016-01-01 06:00:00      Mission      9\n",
       "4 2016-01-01 06:00:00     Nob Hill      5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from safety_events_cities.milestone3 import load_data\\n\\ndf = load_data(\\n    \\\"../data/safety-SanFrancisco-2.parquet\\\",\\n    category=\\\"Street and Sidewalk Cleaning\\\",\\n    years=[2016, 2017, 2018, 2019],\\n    freq=\\\"6H\\\",\\n)\\n\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"from safety_events_cities.milestone3 import load_data\\n\\ndf = load_data(\\n    \\\"../data/safety-SanFrancisco-2.parquet\\\",\\n    category=\\\"Street and Sidewalk Cleaning\\\",\\n    years=[2016, 2017, 2018, 2019],\\n    freq=\\\"6H\\\",\\n)\\n\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from safety_events_cities.milestone3 import load_data\n",
    "\n",
    "df = load_data(\n",
    "    \"../data/safety-SanFrancisco-2.parquet\",\n",
    "    category=\"Street and Sidewalk Cleaning\",\n",
    "    years=[2016, 2017, 2018, 2019],\n",
    "    freq=\"6H\",\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Using external data\n",
    "\n",
    "To enrich the features available for modeling, we will add two externals dataset, in particular holiday and weather data.\n",
    "\n",
    "###  1.1 Taking into account holidays\n",
    "\n",
    "Federal US holidays as well as local state holidays for California can be obtained with the \n",
    "[holidays](https://pypi.org/project/holidays/) package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"from datetime import date\\nimport holidays\";\n",
       "                var nbb_formatted_code = \"from datetime import date\\nimport holidays\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import date\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new boolean column to indicate whether a given date is a holiday,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approximately evaluate the impact of the added variable, we can compare the mean number of events per day on a holiday and a non holiday day. There are 7-25% fewer events of the considered type during holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we create an new boolean variable for dates corresponding to holiday eves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Weather data\n",
    "\n",
    "We next load the [weather data](https://docs.opendata.aws/noaa-ghcn-pds/readme.html) from the NOAA Global Historical Climatology Network. The data is already with daily periodicity, however the values for different sensors are encoded row wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `set_index` followed by `unstack` pandas methods, to create a pivot table where each field has a separate column. Another important step is that we need to fill missing values, using either previous or following values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's visualize the mean daily temperature,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to merge the weather information with the original data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the relevance of added features on the target variable, we can compute the Pearson correlation between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no strong linear correlation between weather and the number of events that we are trying to predict. However a non-linear model model, as used in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient boosting model\n",
    "\n",
    "Gradient boosting decision trees (GBDT) is accurate and effective off-the-shelf algorithm for regression or classification that works well that is suitable to tabular data. Here we will use the histogram based variation included in scikit-learn (`HistGradientBoostingRegressor`) that is inspired by [LightGBM](https://lightgbm.readthedocs.io/en/latest/).\n",
    "\n",
    "We re-create similar preprocessing pipeline to that of step 2 except for using OrdinalEncoder instead of OneHotEncoder, as tree based models are not suitable for very high dimensional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To more reliably evaluate the model performance we can also compute these metrics with time based cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper-parameter search\n",
    "\n",
    "For finding optimal hyper-parameters, we are interested both in better test\n",
    "scores but also in reducing overfitting to make the model more robust. The\n",
    "latter is particularly important given that the training set it small with only\n",
    "a few 1000s samples and we can easily overfit.  Because there are numerous\n",
    "hyper-parameters to test, we have sampled them randomly with\n",
    "`RandomizedSearchCV` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that adding L2 regularisation has a\n",
    "similar effect to reducing the maximum depth. The Poisson loss also provides\n",
    "very competitive results which is consistent with it being suitable for\n",
    "modeling count and frequency data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also useful to visually compare the predicted values with the observed values for different neighborhoods,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reproduce the weekly periodicity and trends, however there is a significant\n",
    "day to day variance that still isn't accounted for by the model.\n",
    "\n",
    "## 4. Other attempted approaches\n",
    "\n",
    "Following approaches were attempted but did not yield a measurable improvement in results,\n",
    "- applying a transformation to the target variable with [`TransformedTargetRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html) to make its distribution closer to the Normal distribution. Note that when using `HistGradientBoostingRegressor(loss=\"poisson\")` a [log link](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function) is used internally.\n",
    "- weight more recent observations higher during training using exponentially decreasing `sample_weight`.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We have explored several approaches for improving the predictions, randing from using external datasets to searching optimal hyper-parameters. To explore, we could also try a purely time series based approach with for instance the [fb-prothet](https://facebook.github.io/prophet/) package.\n",
    "\n",
    "In the following milestone we will see try to make the current model more interpretable and evaluate the possibility of bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
